{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyNtgZF8ADQcar0Dm3ItzV19",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kr-pushpam/DeepGenerativeModel_Aug24/blob/main/CNN_Classification_Animal_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaWIMCbN1ZjS",
        "outputId": "6a706f84-b373-48ff-b60f-7179c4fd1637"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown  # gdown is used to download files from Google Drive\n",
        "import zipfile  # zipfile is used to handle zip files (like extracting them)\n",
        "import os\n",
        "\n",
        "# Google Drive file ID and link for the dataset (source: Google Drive)\n",
        "# The file_id corresponds to the file you want to download from Google Drive\n",
        "# Construct the direct download URL using the file_id, link that allows direct download\n",
        "\n",
        "file_id = '1lBkM874rRc8aTQAI3gn67urH9jh1GgmJ'\n",
        "download_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "output = '/content/animal_dataset.zip'# Define the destination path for the downloaded zip file in Colab's local filesystem\n",
        "gdown.download(download_url, output, quiet=False) # Download the zip file from Google Drive to Colab's local storage i.e. output path\n",
        "\n",
        "extracted_path = '/content/'# Define the extraction path in Colab's local storage where the dataset will be extracted, root in this case\n",
        "\n",
        "# Unzip the downloaded dataset from the zip file (source: the downloaded zip file)\n",
        "# Unzipping the zip file located at 'output' and extracting it to 'extracted_path' , root in this case\n",
        "with zipfile.ZipFile(output, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_path)  # Extract all files to /content/\n",
        "\n",
        "# This lists all the files and directories in the /content/ directory (where the dataset was extracted)\n",
        "print(\"Extracted File\", os.listdir(extracted_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h-zZY6B1i5F",
        "outputId": "2f9ed47d-d7a6-40ce-f104-4a3d7c2feff5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1lBkM874rRc8aTQAI3gn67urH9jh1GgmJ\n",
            "From (redirected): https://drive.google.com/uc?id=1lBkM874rRc8aTQAI3gn67urH9jh1GgmJ&confirm=t&uuid=5fed892e-ac19-4c69-a238-1730baa93fc2\n",
            "To: /content/animal_dataset.zip\n",
            "100%|██████████| 701M/701M [00:02<00:00, 305MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted File ['.config', 'animal_dataset.zip', 'drive', 'Animals_data', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# file management utilities\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "dir_path = \"/content/content/Animals_data_backup\"\n",
        "\n",
        "# shutil.rmtree(dir_path) # remove or delete a given directory\n",
        "shutil.copytree(\"Animals_data\", \"Animals_data_backup\") # copy a given directory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "EeK6rUoT1wHO",
        "outputId": "4f9d0260-0e88-4c40-b0a4-896870c20ef5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Animals_data_backup'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from datetime import date\n",
        "from torchvision import models\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "eZ1i6B-a1a-v"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "if not os.path.exists('/content/working/weights/'):\n",
        "    os.makedirs('/content/working/weights/')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3Cg5Qy51t4Y",
        "outputId": "2de5a48f-076d-4a79-a289-8f7aaadd5fe5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir = \"/content/Animals_data_backup/animals/animals/\"\n",
        "bsz = 16\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((240, 240)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                        [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "#split_data\n",
        "train_dataset = datasets.ImageFolder(root=dataset_dir, transform=data_transforms)\n",
        "train_data, val_data = torch.utils.data.random_split(train_dataset, [int(train_dataset.__len__()*0.8), train_dataset.__len__()-int(train_dataset.__len__()*0.8)])\n",
        "#load_data\n",
        "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=bsz, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_data, batch_size=bsz, shuffle=False)"
      ],
      "metadata": {
        "id": "8KcRKBra2Cmb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of training samples: {len(train_data)}\")\n",
        "print(f\"Number of validation samples: {len(val_data)}\")\n",
        "\n",
        "# Example: Iterate over one batch\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "\n",
        "print(\"Train features batch shape:\", train_features.shape)\n",
        "print(\"Train labels batch shape:\", train_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbRFM_JN2Nco",
        "outputId": "2463c66a-3e79-4463-892b-f1e25205e615"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 4320\n",
            "Number of validation samples: 1080\n",
            "Train features batch shape: torch.Size([16, 3, 240, 240])\n",
            "Train labels batch shape: torch.Size([16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN model (model 3)\n",
        "class Model3(nn.Module):\n",
        "    def __init__(self, num_classes=90):\n",
        "        super(Model3, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)  # Conv2D with padding='same'\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # MaxPool2D(pool_size=(2, 2), strides=2)\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # Instead of hardcoding, use AdaptiveAvgPool2d to ensure the output is fixed-size\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((7, 7))  # You can adjust this to match your final output size\n",
        "\n",
        "        # Define the fully connected layer\n",
        "        self.fc = nn.Linear(64 * 7 * 7, num_classes)  # 64 filters * 7x7 feature map\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))  # Activation\n",
        "        x = self.pool(x)  # Pooling\n",
        "        x = F.relu(self.conv2(x))  # Activation\n",
        "        x = self.pool(x)  # Pooling\n",
        "\n",
        "        # Apply adaptive pooling to get fixed size\n",
        "        x = self.adaptive_pool(x)\n",
        "\n",
        "        x = self.flatten(x)  # Flatten the feature maps into a single vector\n",
        "        x = self.fc(x)  # Fully connected layer\n",
        "        return F.log_softmax(x, dim=1)  # Log softmax for multi-class classification\n",
        "\n",
        "# Instantiate model 3\n",
        "model3 = Model3(num_classes=90)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for multi-class classification\n",
        "optimizer = optim.Adam(model3.parameters(), lr=0.001)  # Adam optimizer with learning rate 0.001\n"
      ],
      "metadata": {
        "id": "qQdp8XNC2UDy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if a GPU is available, otherwise use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Move the model to the device (GPU or CPU)\n",
        "model3.to(device)\n",
        "\n",
        "# Training the model3\n",
        "num_epochs = 10  # Number of epochs\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "# Training and evaluation loop remains the same\n",
        "for epoch in range(num_epochs):\n",
        "    model3.train()  # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass with model 3\n",
        "        outputs = model3(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Validation step for model 3\n",
        "    model3.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model3(images)\n",
        "            val_loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {running_loss/len(train_dataloader):.4f}, Validation Accuracy: {100*correct/total:.2f}%')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsyNZamk2eNr",
        "outputId": "ceeed669-af7c-4b62-98e1-176079921eac"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Training Loss: 4.2996, Validation Accuracy: 9.91%\n",
            "Epoch [2/10], Training Loss: 3.6540, Validation Accuracy: 15.37%\n",
            "Epoch [3/10], Training Loss: 3.1468, Validation Accuracy: 18.52%\n",
            "Epoch [4/10], Training Loss: 2.7756, Validation Accuracy: 20.56%\n",
            "Epoch [5/10], Training Loss: 2.4737, Validation Accuracy: 24.17%\n",
            "Epoch [6/10], Training Loss: 2.1649, Validation Accuracy: 25.09%\n",
            "Epoch [7/10], Training Loss: 1.8856, Validation Accuracy: 28.24%\n",
            "Epoch [8/10], Training Loss: 1.6429, Validation Accuracy: 28.24%\n",
            "Epoch [9/10], Training Loss: 1.4478, Validation Accuracy: 31.02%\n",
            "Epoch [10/10], Training Loss: 1.2396, Validation Accuracy: 32.78%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on the validation data (testing phase)\n",
        "model3.eval()  # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():  # Disable gradient calculations for faster evaluation\n",
        "    for images, labels in val_dataloader:  # Use the validation dataloader for evaluation\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model3(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "val_accuracy = 100 * correct / total\n",
        "print(f'Validation/Test Accuracy: {val_accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Q2R2bXY2xwM",
        "outputId": "253a832d-72c3-4d8b-db23-79b1092457eb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation/Test Accuracy: 32.78%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model parameters to Google Drive\n",
        "model_save_path = '/content/drive/MyDrive/Colab Notebooks/DGM -Aug-2024/cnn_classification_animal.pth'\n",
        "torch.save(model3.state_dict(), model_save_path)"
      ],
      "metadata": {
        "id": "KyFFd0kIBNp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model3.state_dict(), 'cnn_classification_animal.pth')  # Save the model parameters"
      ],
      "metadata": {
        "id": "-gkhRuac2zmi"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Save the model parameters to Google Drive\n",
        "model_save_path = '/content/gdrive/MyDrive/Colab Notebooks/DGM -Aug-2024/cnn_classification_animal.pth'\n",
        "torch.save(model3.state_dict(), model_save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBRf1mBEBUWw",
        "outputId": "7b0193cc-fd7d-4b5f-ca08-5d9b822a776d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Define the path where the model will be saved/loaded\n",
        "model_save_path = '/content/cnn_classification_animal.pth'\n",
        "\n",
        "# Check if the model file already exists\n",
        "if os.path.exists(model_save_path):\n",
        "    print(\"Saved model found. Loading the model for fine-tuning...\")\n",
        "\n",
        "    # Recreate the model architecture\n",
        "    model3 = Model3(num_classes=90)\n",
        "\n",
        "    num_fine_tune_epochs = 10\n",
        "\n",
        "    # Load the saved model weights\n",
        "    model3.load_state_dict(torch.load(model_save_path))\n",
        "\n",
        "    # Move model to the appropriate device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model3.to(device)\n",
        "\n",
        "    # Set the model to training mode for fine-tuning\n",
        "    model3.train()\n",
        "\n",
        "    # Define optimizer and criterion for fine-tuning\n",
        "    optimizer = torch.optim.Adam(model3.parameters(), lr=0.0001)  # Reduced learning rate for fine-tuning\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # Continue training (fine-tuning)\n",
        "    for epoch in range(num_fine_tune_epochs):  # Adjust fine-tuning epochs\n",
        "        for images, labels in train_dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()  # Zero the gradients\n",
        "            outputs = model3(images)  # Forward pass\n",
        "            loss = criterion(outputs, labels)  # Compute the loss\n",
        "            loss.backward()  # Backward pass\n",
        "            optimizer.step()  # Update weights\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_fine_tune_epochs}], Fine-tuning Loss: {loss.item():.4f}')\n",
        "\n",
        "    # Save the fine-tuned model to Google Drive\n",
        "    torch.save(model3.state_dict(), model_save_path)\n",
        "    print(\"Fine-tuned model saved to Google Drive.\")\n",
        "\n",
        "else:\n",
        "    print(\"No saved model found. Starting training from scratch...\")\n",
        "\n",
        "    # Create and initialize the model\n",
        "    model3 = Model3(num_classes=90)\n",
        "\n",
        "    # Move model to the appropriate device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model3.to(device)\n",
        "\n",
        "    # Define optimizer and criterion for training from scratch\n",
        "    optimizer = torch.optim.Adam(model3.parameters(), lr=0.001)  # Standard learning rate for initial training\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # Train the model from scratch\n",
        "    num_epochs = 10  # Adjust based on your needs\n",
        "    for epoch in range(num_epochs):\n",
        "        model3.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for images, labels in train_dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()  # Zero the gradients\n",
        "            outputs = model3(images)  # Forward pass\n",
        "            loss = criterion(outputs, labels)  # Compute the loss\n",
        "            loss.backward()  # Backward pass\n",
        "            optimizer.step()  # Update weights\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {running_loss/len(train_dataloader):.4f}')\n",
        "\n",
        "    # Save the model after initial training\n",
        "    torch.save(model3.state_dict(), model_save_path)\n",
        "    print(\"Model trained and saved to Google Drive.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzNfOMuP_iXM",
        "outputId": "745db81e-6f13-4911-dbb5-2ece39d72b7b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Saved model found. Loading the model for fine-tuning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-b91d45fb8148>:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model3.load_state_dict(torch.load(model_save_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Fine-tuning Loss: 2.9037\n",
            "Epoch [2/10], Fine-tuning Loss: 3.0176\n",
            "Epoch [3/10], Fine-tuning Loss: 3.0339\n",
            "Epoch [4/10], Fine-tuning Loss: 3.3918\n",
            "Epoch [5/10], Fine-tuning Loss: 2.3815\n",
            "Epoch [6/10], Fine-tuning Loss: 1.8801\n",
            "Epoch [7/10], Fine-tuning Loss: 3.3500\n",
            "Epoch [8/10], Fine-tuning Loss: 2.2007\n",
            "Epoch [9/10], Fine-tuning Loss: 1.5112\n",
            "Epoch [10/10], Fine-tuning Loss: 2.0468\n",
            "Fine-tuned model saved to Google Drive.\n"
          ]
        }
      ]
    }
  ]
}